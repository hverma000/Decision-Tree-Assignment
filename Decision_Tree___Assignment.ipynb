{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n"
      ],
      "metadata": {
        "id": "qEjsv2T4_ZLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> A Decision Tree works by asking a sequence of yes/no questions on features, progressively narrowing down until it reaches a decision (class label)."
      ],
      "metadata": {
        "id": "ijOxGn-k_akO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?"
      ],
      "metadata": {
        "id": "q8Vr4jIhAF6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Both Gini and Entropy measure how mixed the classes are in a node.\n",
        "\n",
        "The Decision Tree algorithm uses them to decide where to split so that resulting nodes are as pure (homogeneous) as possible."
      ],
      "metadata": {
        "id": "pmyUIXpsAYUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n"
      ],
      "metadata": {
        "id": "PxbP0maiAbns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Pre-Pruning = Stop early (speed focus).\n",
        "\n",
        "Post-Pruning = Grow then cut (accuracy focus)."
      ],
      "metadata": {
        "id": "Dx5R990UBHgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n"
      ],
      "metadata": {
        "id": "ACKR8-L0BqjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Information Gain = Reduction in entropy after a split.\n",
        "\n",
        "Important because it helps the Decision Tree pick the best feature that maximizes purity and improves predictive power."
      ],
      "metadata": {
        "id": "bb3K6LRpBrRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n"
      ],
      "metadata": {
        "id": "2OurJLmfBwx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Applications: Finance, healthcare, marketing, retail, manufacturing, etc.\n",
        "\n",
        "Advantages: Simple, interpretable, fast, versatile.\n",
        "\n",
        "Limitations: Overfitting, instability, sometimes lower accuracy."
      ],
      "metadata": {
        "id": "DHBGMFcUDTaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances\n",
        "  "
      ],
      "metadata": {
        "id": "RklEFA-TDcc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8nHws0fE1Kl",
        "outputId": "d9cdeec0-d466-4ca0-9654-c303d6e9405e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n",
            "\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.8933\n",
            "petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n"
      ],
      "metadata": {
        "id": "nqbYjxtwFpkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "clf_depth3 = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf_depth3.fit(X_train, y_train)\n",
        "y_pred_depth3 = clf_depth3.predict(X_test)\n",
        "accuracy_depth3 = accuracy_score(y_test, y_pred_depth3)\n",
        "\n",
        "clf_full = DecisionTreeClassifier(random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "print(\"Decision Tree with max_depth=3 Accuracy:\", accuracy_depth3)\n",
        "print(\"Fully-grown Decision Tree Accuracy:\", accuracy_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGHva2JYF3qp",
        "outputId": "8575300e-7ec4-4ecb-806f-af8912000cc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree with max_depth=3 Accuracy: 1.0\n",
            "Fully-grown Decision Tree Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "● Load the Boston Housing Dataset\n",
        "● Train a Decision Tree Regressor\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n"
      ],
      "metadata": {
        "id": "rG_Mso44GX8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
        "X, y = boston.data, boston.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(boston.feature_names, regressor.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL3t4RZuG_vP",
        "outputId": "3bef93e2-07f6-4653-c25e-e88a0dbe60ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/datasets/_openml.py:75: RuntimeWarning: Invalid cache, redownloading file\n",
            "  warn(\"Invalid cache, redownloading file\", RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 11.588026315789474\n",
            "\n",
            "Feature Importances:\n",
            "CRIM: 0.0585\n",
            "ZN: 0.0010\n",
            "INDUS: 0.0099\n",
            "CHAS: 0.0003\n",
            "NOX: 0.0071\n",
            "RM: 0.5758\n",
            "AGE: 0.0072\n",
            "DIS: 0.1096\n",
            "RAD: 0.0016\n",
            "TAX: 0.0022\n",
            "PTRATIO: 0.0250\n",
            "B: 0.0119\n",
            "LSTAT: 0.1900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "● Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "9lnHEsxAIiZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    \"max_depth\": [2, 3, 4, 5, None],\n",
        "    \"min_samples_split\": [2, 3, 4, 5, 10]\n",
        "}\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Parameters:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8n40mAWI0GV",
        "outputId": "5d5f9ecb-35f4-43d2-f9e4-9b1a070848c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 10}\n",
            "Test Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    }
  ]
}